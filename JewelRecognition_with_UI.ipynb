{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-etzm6vAxnXy",
        "outputId": "a9eeeb5b-a980-4da4-f934-866da7193cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/JeweleryRecognition\"\n",
        "image_dir = os.path.join(base_dir, \"Images\")\n",
        "csv_path = os.path.join(base_dir, \"Labels.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KETfBcgTmU6p",
        "outputId": "29e1718a-ab90-4553-ec75-040409444344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (6.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-a2mp4h2g\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-a2mp4h2g\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (6.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aF9IfYJdmYbM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "df['filepath'] = df['FILENAME'].apply(lambda x: os.path.join(image_dir, x))\n",
        "df = df[df['filepath'].apply(os.path.exists)].reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YclHGnmV8gxo",
        "outputId": "ec95a843-9f3a-4388-f628-5e7b2c4915f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:15<00:00,  1.59it/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import clip\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "def extract_features(image_paths):\n",
        "    features = []\n",
        "    for path in tqdm(image_paths):\n",
        "        image = preprocess(Image.open(path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            feature = model.encode_image(image).cpu().numpy()\n",
        "        features.append(feature[0])\n",
        "    return features\n",
        "\n",
        "image_features = extract_features(df['filepath'].tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-f4UESmO8jBm"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "features_np = np.array(image_features).astype(\"float32\")\n",
        "faiss.normalize_L2(features_np)\n",
        "\n",
        "index = faiss.IndexFlatIP(features_np.shape[1])\n",
        "index.add(features_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iNpzTBBtkM_4",
        "outputId": "155eb4fb-1ea5-4567-ad9c-db985a3e90ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.29.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.10)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "pZf0v5GQ1Pi9",
        "outputId": "8ab742e2-8830-4124-90f7-70c648990a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5009e74860a8d9feec.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5009e74860a8d9feec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import math\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "stored_state = {\"query_image\": None}\n",
        "\n",
        "def run_search(input_image):\n",
        "    if input_image is None:\n",
        "        return gr.update(value=\"❗ Please upload an image.\"), None, gr.update(visible=True), gr.update(visible=False)\n",
        "\n",
        "    if not is_jewellery(input_image):\n",
        "        return gr.update(value=\"🚫 That doesn’t look like jewellery. Try another image.\"), None, gr.update(visible=True), gr.update(visible=False)\n",
        "\n",
        "    stored_state[\"query_image\"] = input_image\n",
        "    img_t = preprocess(input_image.convert(\"RGB\")).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        feats = model.encode_image(img_t).cpu().numpy().astype(\"float32\")\n",
        "    faiss.normalize_L2(feats)\n",
        "    D, I = index.search(feats, k=5)\n",
        "    idxs = [i for i, d in zip(I[0], D[0]) if d >= 0.25]\n",
        "    if not idxs:\n",
        "        return gr.update(value=\"🔍 No matches found.\"), None, gr.update(visible=False), gr.update(visible=True)\n",
        "\n",
        "    df_sim = df.iloc[idxs]\n",
        "    imgs = [input_image] + [Image.open(p) for p in df_sim['filepath']]\n",
        "    caps = [\"Query Image\"] + [f\"{r['FILENAME']}\\n{r['JEWELLERY_TYPE']} | {r['METAL_USED']}\" for _, r in df_sim.iterrows()]\n",
        "    cols, rows = 3, math.ceil(len(imgs) / 3)\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n",
        "    axs = axs.flatten()\n",
        "    for ax in axs:\n",
        "        ax.axis(\"off\")\n",
        "    for i, im in enumerate(imgs):\n",
        "        axs[i].imshow(im)\n",
        "        axs[i].set_title(caps[i], fontsize=10)\n",
        "    plt.tight_layout()\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format=\"png\")\n",
        "    plt.close(fig)\n",
        "    buf.seek(0)\n",
        "    result_img = Image.open(buf)\n",
        "    return gr.update(value=\"✅ Matches found!\"), result_img, gr.update(visible=False), gr.update(visible=True)\n",
        "\n",
        "def go_back():\n",
        "    stored_state[\"query_image\"] = None\n",
        "    return None, \"\", gr.update(visible=True), gr.update(visible=False)\n",
        "\n",
        "with gr.Blocks(title=\"JewelVision\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Playfair+Display:wght@700&family=Roboto:wght@400&display=swap\" rel=\"stylesheet\">\n",
        "<div class=\"navbar\">\n",
        "    <div class=\"nav-logo\">🔶 JewelVision</div>\n",
        "    <div class=\"nav-links\">\n",
        "        <a href=\"#\">Home</a>\n",
        "        <a href=\"#\">About</a>\n",
        "        <a href=\"#\">Upload</a>\n",
        "        <a href=\"#\">Contact</a>\n",
        "    </div>\n",
        "</div>\n",
        "\n",
        "<div class=\"main-header fade-in\">\n",
        "    <h1>JewelVision</h1>\n",
        "    <p>Discover similar jewellery styles with AI-powered image search</p>\n",
        "</div>\n",
        "\"\"\")\n",
        "\n",
        "    with gr.Column(visible=True, elem_id=\"search-col\") as search_col:\n",
        "        gr.Markdown(\"<h3 style='text-align:center;'>Upload a Jewellery Image 💍</h3>\")\n",
        "        image_in = gr.Image(type=\"pil\", label=\"\", width=400)\n",
        "        status_txt = gr.Textbox(\n",
        "            label=\"\", interactive=False, lines=1,\n",
        "            value=\"Please upload a jewellery image.\",\n",
        "            show_label=False,\n",
        "            elem_classes=\"status-txt\"\n",
        "        )\n",
        "\n",
        "    with gr.Column(visible=False, elem_id=\"results-col\") as results_col:\n",
        "        gr.Markdown(\"<h3 style='text-align:center;'>🎯 Similar Matches</h3>\")\n",
        "        output_img = gr.Image(show_label=False, width=1000)\n",
        "        back_btn = gr.Button(\"⬅️ Back to Search\", elem_classes=\"back-button\")\n",
        "\n",
        "    image_in.change(fn=run_search, inputs=[image_in],\n",
        "                    outputs=[status_txt, output_img, search_col, results_col])\n",
        "    back_btn.click(fn=go_back, inputs=[],\n",
        "                   outputs=[image_in, status_txt, search_col, results_col])\n",
        "\n",
        "    demo.css = \"\"\"\n",
        ".navbar {\n",
        "    display: flex;\n",
        "    justify-content: space-between;\n",
        "    align-items: center;\n",
        "    background-color: #f8f1e4;\n",
        "    padding: 15px 30px;\n",
        "    border-bottom: 2px solid #e0d2b6;\n",
        "    font-family: 'Roboto', sans-serif;\n",
        "    box-shadow: 0 4px 8px rgba(0,0,0,0.1);\n",
        "    position: sticky;\n",
        "    top: 0;\n",
        "    z-index: 10;\n",
        "}\n",
        ".nav-logo {\n",
        "    font-size: 1.6em;\n",
        "    font-weight: bold;\n",
        "    color: #d4af37;\n",
        "}\n",
        ".nav-links a {\n",
        "    margin-left: 25px;\n",
        "    text-decoration: none;\n",
        "    color: #4B3B2B;\n",
        "    font-weight: 500;\n",
        "    transition: color 0.3s ease, transform 0.3s ease;\n",
        "}\n",
        ".nav-links a:hover {\n",
        "    color: #d4af37;\n",
        "    transform: translateY(-2px);\n",
        "}\n",
        ".main-header {\n",
        "    text-align: center;\n",
        "    padding: 30px;\n",
        "    animation: fadeInUp 1s ease-in-out;\n",
        "}\n",
        ".main-header h1 {\n",
        "    font-family: 'Playfair Display', serif;\n",
        "    font-size: 4em;\n",
        "    color: #d4af37;\n",
        "    margin: 0;\n",
        "}\n",
        ".main-header p {\n",
        "    font-size: 1.5em;\n",
        "    color: #4B3B2B;\n",
        "    font-family: 'Roboto', sans-serif;\n",
        "}\n",
        "#search-col, #results-col {\n",
        "    align-items: center;\n",
        "    padding: 25px;\n",
        "    background: #fff8f0;\n",
        "    border-radius: 20px;\n",
        "    box-shadow: 0 0 20px rgba(0,0,0,0.1);\n",
        "}\n",
        ".back-button {\n",
        "    background: #8B4513;\n",
        "    color: white;\n",
        "    font-weight: bold;\n",
        "    padding: 12px 25px;\n",
        "    border-radius: 10px;\n",
        "    margin-top: 15px;\n",
        "}\n",
        ".back-button:hover {\n",
        "    background: #A0522D;\n",
        "}\n",
        ".status-txt textarea {\n",
        "    text-align: center !important;\n",
        "    font-weight: 600;\n",
        "    font-size: 1.2em;\n",
        "    color: #4B3B2B;\n",
        "}\n",
        "body, .gradio-container, h1, h3, p, label {\n",
        "    text-align: center !important;\n",
        "    font-family: 'Roboto', sans-serif;\n",
        "}\n",
        "input[type=\"file\"] {\n",
        "    margin-top: 15px;\n",
        "    text-align: center;\n",
        "}\n",
        "@keyframes fadeInUp {\n",
        "    from {\n",
        "        opacity: 0;\n",
        "        transform: translateY(30px);\n",
        "    }\n",
        "    to {\n",
        "        opacity: 1;\n",
        "        transform: translateY(0);\n",
        "    }\n",
        "}\n",
        ".fade-in {\n",
        "    animation: fadeInUp 1s ease-in-out;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}